---
title: Zombie links on data catalogs
description: Some of these links were less dead than I'd thought.
tweet_text: Are they dead, or are they alive? http://thomaslevine.com/!/data-catalog-dead-links #opendata
twitter_image: figure/prop_links.png
facebook_image: figure/prop_links.png
tags: ['open-data']
kind: article
created_at: 2014-01-28
---
```{r configure, echo=FALSE}
opts_chunk$set(echo = FALSE, dpi = 42 * 5)
```
After I wrote about
[dead links on data catalogs](/!/dead-links-on-data-catalogs),
some people commented that the links were less dead than I'd thought.


Some explanations were proposed.

**CKAN fails on HEAD requests**

**Redirects (Waldo)**

What was really going on?

## Status codes
I called a URL alive if an ordinary HEAD request to it returned a
[status code](http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html) of 200.
This simplifies things a little bit.

Here are all of the status codes that I received, from all of the different
links from all of the catalogs.

```{r status_codes}
p.codes
```

Let's look at this plot for just the specific catalogs that those Tweets were
about.




It seems like there were a lot of non-responses,

```r
sort(table(subset(datasets, catalog == 'data.openva.com')$status_code), decreasing = T)[1:5]
```

```r
sort(table(subset(datasets, catalog == 'dati.trentino.it')$status_code), decreasing = T)[1:5]
```

but that doesn't fully explain the results in the chart from the other post.
It looks like I have duplicate records in the table.

    select catalog, identifier, count(*) from links where software = 'ckan' group by catalog, identifier order by count(*) desc limit 1;



I had thought that there was a unique index on
`links.software, links.catalog, links.identifier`,
but there wasn't!



also, I had interpreted NULL as meaning that the dataset is not a link,
but it really represents that link's liveliness has yet  to be checked.

    url_list = [row['url'] for row in dt.execute('SELECT DISTINCT url FROM links WHERE status_code IS NULL')]


Here are some non-link datasets in the links table.

    select 'https://' || links.catalog || '/d/' || id url from links join socrata where not is_link and links.identifier=socrata.tableId limit 10;                                                                         
    url                               
    ----------------------------------
    https://data.sfgov.org/d/3fig-nit3
    https://data.sfgov.org/d/3hay-yzem
    https://data.sfgov.org/d/3nwz-3n68
    https://data.sfgov.org/d/3twj-ueew
    https://data.sfgov.org/d/4ang-frd3
    https://data.sfgov.org/d/5q3n-q6kw
    https://data.sfgov.org/d/7ybj-xpju
    https://data.sfgov.org/d/99js-dqmz
    https://data.sfgov.org/d/akvp-jmwa
    https://data.sfgov.org/d/di4e-7emh


I ran again things that timed out.
I checked a few manually.

dati.trentino.it/storage/f/2013-06-16T111814/_ggeiWE.csv

This works but sometimes takes a while.

https://www-genesis.destatis.de/genesis/online/link/tabelleDownload/46421-0001.html

In case the problem was an internet connection (tethered from a phone),
I used a big-boy computer in a datacenter to run the checker again on
all datasets that had timed out. Results didn't remarkably change.





## Slow datasets
Now I think this is what was going on.

  url = 'http://dati.trentino.it/storage/f/2013-06-16T114537/_EBmYVk.csv'
  import requests

  get = requests.get(url)
  head = requests.head(url)                                                                                     

  print(get)
  # <Response [200]>

  print(head)
  # <Response [200]>

  print(head.elapsed)
  # datetime.timedelta(0, 3, 353558)

The link is alive, but my timeout of 4 seconds (originally 2 seconds)
might be too short. It would have worked in this case, but it came kind
of close.











A bunch of datasets have listed links but provided an empty URL.

    select catalog,count(*) from links where is_link and url is null group by catalog order by 2;



sqlite> select count(*) from links where url like '//%';
0



I didn't have good error logs, so I fixed that.
